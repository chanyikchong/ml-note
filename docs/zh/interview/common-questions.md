# 常见机器学习面试问题

机器学习面试中常见问题及简明答案合集。

---

## 基础知识

### 问：什么是偏差-方差权衡？

**答**：偏差-方差权衡描述了模型简单性和复杂性之间的张力：
- **高偏差**：模型太简单，欠拟合（遗漏模式）
- **高方差**：模型太复杂，过拟合（记忆噪声）

**总误差** = 偏差² + 方差 + 不可约噪声

简单模型 → 高偏差，低方差
复杂模型 → 低偏差，高方差

**解决方案**：通过交叉验证、正则化或集成方法找到最佳点。

---

### 问：解释过拟合及如何预防。

**答**：过拟合发生在模型学习训练数据中的噪声而非一般模式时。

**迹象**：训练和验证性能之间存在较大差距。

**预防方法**：
1. 更多训练数据
2. 正则化（L1、L2）
3. 早停
4. Dropout（神经网络）
5. 交叉验证
6. 更简单的模型架构
7. 数据增强

---

### 问：L1和L2正则化有什么区别？

**答**：

| 方面 | L1 (Lasso) | L2 (Ridge) |
|------|-----------|-----------|
| 惩罚 | $\lambda\sum|w_i|$ | $\lambda\sum w_i^2$ |
| 效果 | 稀疏权重（特征选择） | 小权重（收缩） |
| 解 | 在0处不可微 | 闭式解 |
| 使用场景 | 需要特征选择时 | 所有特征相关时 |

---

### 问：什么时候使用交叉验证vs保留测试集？

**答**：
- **交叉验证**：数据有限时，需要稳健估计
- **保留测试**：数据充足时，最终无偏评估

**重要**：测试集应只使用一次用于最终评估。永远不要在测试集上调整超参数。

---

## 模型

### 问：解释决策树如何分裂。

**答**：决策树递归分裂数据以最大化纯度：

1. 计算当前节点的不纯度（Gini或熵）
2. 对每个特征和阈值，计算信息增益
3. 选择最大化信息增益的分裂
4. 重复直到停止条件（最大深度、最小样本）

**Gini**：$1 - \sum p_c^2$
**熵**：$-\sum p_c \log p_c$

---

### 问：为什么用随机森林而不是单棵决策树？

**答**：

| 方面 | 单棵树 | 随机森林 |
|------|--------|----------|
| 方差 | 高 | 低（集成平均） |
| 可解释性 | 高 | 较低 |
| 过拟合 | 容易 | 抗性 |
| 训练 | 快 | 可并行 |

随机森林通过以下方式降低方差：
1. **Bagging**：在自助样本上训练
2. **特征随机性**：每次分裂考虑特征子集

---

### 问：概念性解释梯度提升。

**答**：梯度提升顺序构建模型：

1. 从简单预测开始（如均值）
2. 计算残差（误差）
3. 训练新模型预测残差
4. 将新模型添加到集成（带学习率）
5. 重复

**关键公式**：$F_m(x) = F_{m-1}(x) + \eta \cdot h_m(x)$

每棵新树纠正先前的错误。集成加性增长。

---

### 问：什么时候用SVM vs 逻辑回归？

**答**：

| 方面 | 逻辑回归 | SVM |
|------|---------|-----|
| 输出 | 概率 | 仅类别（除非校准） |
| 决策边界 | 考虑所有点 | 只有支持向量 |
| 非线性 | 特征工程 | 核技巧 |
| 高维 | 可能过拟合 | 效果好（最大间隔） |
| 训练速度 | 快 | 较慢（特别是核） |

**经验法则**：从逻辑回归开始；对高维小数据集用SVM。

---

### 问：PCA如何工作？

**答**：PCA找到最大方差的正交方向：

1. 中心化数据（减去均值）
2. 计算协方差矩阵
3. 找特征向量和特征值
4. 按特征值排序（降序）
5. 将数据投影到前k个特征向量

**关键见解**：第一主成分 = 最大方差方向。

---

## 深度学习

### 问：为什么使用激活函数？

**答**：激活函数引入非线性。没有它们，多层会坍缩为单个线性变换。

**常见激活**：
- **ReLU**：$\max(0, x)$ — 快速，避免梯度消失
- **Sigmoid**：$(1 + e^{-x})^{-1}$ — 输出概率，有梯度消失问题
- **Tanh**：中心化输出，仍有梯度问题

---

### 问：解释梯度消失/爆炸。

**答**：
- **消失**：梯度在层间指数缩小（sigmoid，深网络）
- **爆炸**：梯度指数增长（训练不稳定）

**解决方案**：
1. ReLU激活（无饱和）
2. 批量/层归一化
3. 跳跃连接（ResNet）
4. 正确初始化（He, Xavier）
5. 梯度裁剪（针对爆炸）

---

### 问：BatchNorm做什么？

**答**：BatchNorm跨批次归一化层输入：

$$\hat{x} = \frac{x - \mu_{batch}}{\sqrt{\sigma^2_{batch} + \epsilon}}$$

$$y = \gamma \hat{x} + \beta$$

**好处**：
1. 更快训练（更高学习率）
2. 正则化效果
3. 减少内部协变量偏移

**注意**：训练和测试时行为不同。

---

### 问：什么时候用CNN vs RNN vs Transformer？

**答**：

| 架构 | 用例 | 关键特征 |
|------|------|----------|
| CNN | 图像，网格数据 | 局部模式，平移不变 |
| RNN/LSTM | 序列（短） | 记忆，顺序处理 |
| Transformer | 文本，长序列 | 注意力，可并行 |

现代趋势：Transformer越来越多用于图像（ViT）和音频。

---

## 实用机器学习

### 问：如何处理不平衡数据集？

**答**：

1. **重采样**：过采样少数类（SMOTE）或欠采样多数类
2. **类别权重**：少数类错误更高惩罚
3. **阈值调整**：训练后调整决策边界
4. **不同指标**：用PR-AUC、F1而非准确率
5. **异常检测**：极端不平衡时

**关键**：总是在训练-测试划分后重采样（只对训练数据）。

---

### 问：什么时候用精确率vs召回率？

**答**：
- **精确率**（预测为正的，多少正确）：假阳性代价高时用（垃圾邮件过滤器，医学筛查第二阶段）
- **召回率**（实际为正的，找到多少）：假阴性代价高时用（疾病检测，欺诈）

**F1分数**平衡两者：$F1 = 2 \cdot \frac{precision \cdot recall}{precision + recall}$

---

### 问：什么是数据泄露？

**答**：数据泄露发生在训练集外的信息影响模型时：

**类型**：
1. **目标泄露**：特征从目标派生
2. **训练-测试污染**：测试数据在训练期间被看到

**预防**：
1. 先划分数据
2. 只在训练集上拟合转换器
3. 特征中无未来信息
4. 小心时间序列

---

### 问：如何解释模型预测？

**答**：

**方法**：
1. **特征重要性**：哪些特征最重要
2. **SHAP值**：每个特征对预测的贡献
3. **部分依赖图**：特征如何影响输出
4. **LIME**：局部线性近似

**对于利益相关者**：使用具体例子；用业务术语解释。

---

### 问：如何处理缺失值？

**答**：

| 方法 | 何时使用 |
|------|----------|
| 删除行 | 少量缺失，随机模式 |
| 均值/中位数 | 数值型，简单 |
| 众数 | 类别型 |
| 基于模型（KNN） | 复杂模式 |
| 指示变量 | 缺失有信息量 |

**始终**：在训练集上拟合填充器，用相同值变换测试集。

---

## 系统设计

### 问：如何设计推荐系统？

**答**：

**方法**：
1. **协同过滤**：用户-物品交互（矩阵分解）
2. **基于内容**：物品特征匹配用户偏好
3. **混合**：结合两者

**考虑**：
- 冷启动问题（新用户/物品）
- 可扩展性（数百万用户/物品）
- 实时vs批处理
- 评估：点击率，参与度

---

### 问：如何在生产中监控模型？

**答**：

**监控**：
1. **数据漂移**：输入分布变化（PSI，KL散度）
2. **概念漂移**：X和Y之间关系变化
3. **性能下降**：当标签可用时
4. **系统健康**：延迟，错误，吞吐量

**行动**：警报，自动重训练触发器，更新的A/B测试。

---

### 问：批量学习和在线学习有什么区别？

**答**：

| 方面 | 批量 | 在线 |
|------|------|------|
| 训练 | 所有数据一次 | 一次一个样本 |
| 更新 | 定期重训练 | 持续 |
| 内存 | 需要所有数据 | 最小 |
| 用例 | 静态问题 | 变化模式 |

**在线学习**：适用于流数据，不适合内存的大数据集。

---

## 行为问题

### 问：描述一个有挑战性的ML项目以及你如何解决它。

**框架**：
1. **情境**：问题是什么？
2. **任务**：你的角色是什么？
3. **行动**：你尝试了什么方法？
4. **结果**：结果如何？指标提高了吗？

**提示**：具体说明技术细节，展示迭代解决问题的过程。

---

### 问：如何决定使用什么模型？

**答**：

1. **从简单开始**：线性/逻辑回归作为基线
2. **考虑数据**：大小、类型（表格/图像/文本）、质量
3. **考虑需求**：可解释性、速度、准确性
4. **迭代**：尝试多种方法，公平比较

**常见选择**：
- 表格：从梯度提升开始（XGBoost, LightGBM）
- 文本/图像：深度学习（Transformer, CNN）
- 小数据：更简单模型，迁移学习
